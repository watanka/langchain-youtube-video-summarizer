{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Xoo7NZTn6F"
      },
      "source": [
        "# YouTube Video Summarization\n",
        "\n",
        "유튜브 [빵형의 개발도상국](https://www.youtube.com/@bbanghyong)\n",
        "\n",
        "1. 유튜브 영상 다운로드 (음성만 다운로드, mp3) - PyTube\n",
        "2. Speech to Text (Transcribe) - OpenAI Whisper (Local)\n",
        "3. **Map-reduce** summariation - LangChain, OpenAI ChatGPT API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEWAygaxWfZs",
        "outputId": "084a00bc-6fea-458b-c8b2-bc6e6d9875a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'sudo'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
            "[notice] To update, run: C:\\Users\\user\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
            "[notice] To update, run: C:\\Users\\user\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install -q openai-whisper pytube\n",
        "!pip install -q openai tiktoken langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdwIV5IDUM_b"
      },
      "source": [
        "## Download YouTube video\n",
        "\n",
        "[나이가 들수록 좁아지고 재미없는 인간관계... 활력을 얻으려면 어떻게 해야 할까](https://www.youtube.com/watch?v=GkhIVshS7jM) - 충코의 철학 유튜브 채널"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Z0MVmwOQX0Ko",
        "outputId": "4bbd761b-8445-447f-b48d-7712e5b07c72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\user\\\\Desktop\\\\projects\\\\langchain_project\\\\.\\\\input.mp3'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "yt = YouTube('https://www.youtube.com/watch?v=n0ohPOvGN4E')\n",
        "\n",
        "yt.streams.filter(only_audio=True).first().download(\n",
        "    output_path='.', filename='input.mp3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\user\\\\Desktop\\\\projects\\\\langchain_project\\\\.\\\\input.mp3'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pytube import YouTube\n",
        "from pytube.exceptions import VideoUnavailable, RegexMatchError\n",
        "\n",
        "url = 'https://www.youtube.com/watch?v=9xiFa5e6H7c'\n",
        "try :\n",
        "    yt = YouTube(url)\n",
        "except RegexMatchError :\n",
        "    print(f'Video {url} is unavailable')\n",
        "\n",
        "\n",
        "yt.streams.filter(only_audio=True).first().download(\n",
        "    output_path='.', filename='input.mp3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yt.title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkFBJYpGUQoI"
      },
      "source": [
        "## Transcribe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVlpeceUXPkU",
        "outputId": "95fd096b-1fbb-4636-e0df-955a172c7dc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 72.1M/72.1M [00:07<00:00, 10.2MiB/s]\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"tiny\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio = whisper.load_audio('input.mp3')\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([80, 3000])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: ko\n"
          ]
        }
      ],
      "source": [
        "_, probs = model.detect_language(mel)\n",
        "print(f'Detected language: {max(probs, key = probs.get)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecodingOptions(task='transcribe', language=None, temperature=0.0, sample_len=None, best_of=None, beam_size=None, patience=None, length_penalty=None, prompt=None, prefix=None, suppress_tokens='-1', suppress_blank=True, without_timestamps=False, max_initial_timestamp=1.0, fp16=True)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "options = whisper.DecodingOptions()\n",
        "options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = whisper.decode(model, mel, options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class OnnxWhisperModel(nn.Module) :\n",
        "    def __init__(self, original_model) :\n",
        "        super().__init__()\n",
        "        self.original_model = original_model\n",
        "\n",
        "    def forward(self, x) :\n",
        "        return self.original_model.transcribe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======= Diagnostic Run torch.onnx.export version 2.0.0.dev20230220+cu117 =======\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Whisper.forward() missing 1 required positional argument: 'tokens'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\user\\Desktop\\projects\\langchain_project\\유튜브_영상_요약_인공지능_빵형의_개발도상국.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/projects/langchain_project/%EC%9C%A0%ED%8A%9C%EB%B8%8C_%EC%98%81%EC%83%81_%EC%9A%94%EC%95%BD_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dummy_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m80\u001b[39m, \u001b[39m3000\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/projects/langchain_project/%EC%9C%A0%ED%8A%9C%EB%B8%8C_%EC%98%81%EC%83%81_%EC%9A%94%EC%95%BD_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/projects/langchain_project/%EC%9C%A0%ED%8A%9C%EB%B8%8C_%EC%98%81%EC%83%81_%EC%9A%94%EC%95%BD_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD.ipynb#X46sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(model, dummy_input, \u001b[39m'\u001b[39;49m\u001b[39mwhisper_model.onnx\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\onnx\\utils.py:506\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[0;32m    190\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     export_modules_as_functions: Union[\u001b[39mbool\u001b[39m, Collection[Type[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule]]] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    207\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 506\u001b[0m     _export(\n\u001b[0;32m    507\u001b[0m         model,\n\u001b[0;32m    508\u001b[0m         args,\n\u001b[0;32m    509\u001b[0m         f,\n\u001b[0;32m    510\u001b[0m         export_params,\n\u001b[0;32m    511\u001b[0m         verbose,\n\u001b[0;32m    512\u001b[0m         training,\n\u001b[0;32m    513\u001b[0m         input_names,\n\u001b[0;32m    514\u001b[0m         output_names,\n\u001b[0;32m    515\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[0;32m    516\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[0;32m    517\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[0;32m    518\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[0;32m    519\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[0;32m    520\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[0;32m    521\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[0;32m    522\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\onnx\\utils.py:1548\u001b[0m, in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[0;32m   1545\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[0;32m   1546\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[1;32m-> 1548\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[0;32m   1549\u001b[0m     model,\n\u001b[0;32m   1550\u001b[0m     args,\n\u001b[0;32m   1551\u001b[0m     verbose,\n\u001b[0;32m   1552\u001b[0m     input_names,\n\u001b[0;32m   1553\u001b[0m     output_names,\n\u001b[0;32m   1554\u001b[0m     operator_export_type,\n\u001b[0;32m   1555\u001b[0m     val_do_constant_folding,\n\u001b[0;32m   1556\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[0;32m   1557\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m   1558\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[0;32m   1559\u001b[0m )\n\u001b[0;32m   1561\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[0;32m   1563\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _exporter_states\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[0;32m   1564\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\onnx\\utils.py:1113\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[1;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[0;32m   1110\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[0;32m   1112\u001b[0m model \u001b[39m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[1;32m-> 1113\u001b[0m graph, params, torch_out, module \u001b[39m=\u001b[39m _create_jit_graph(model, args)\n\u001b[0;32m   1114\u001b[0m params_dict \u001b[39m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[0;32m   1116\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\onnx\\utils.py:989\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[1;34m(model, args)\u001b[0m\n\u001b[0;32m    984\u001b[0m     graph \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[0;32m    985\u001b[0m         graph, flattened_args, param_count_list, \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     )\n\u001b[0;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, params, torch_out, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m graph, torch_out \u001b[39m=\u001b[39m _trace_and_get_graph_from_model(model, args)\n\u001b[0;32m    990\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m    991\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_unique_state_dict(model)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\onnx\\utils.py:893\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[1;34m(model, args)\u001b[0m\n\u001b[0;32m    891\u001b[0m prev_autocast_cache_enabled \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_autocast_cache_enabled()\n\u001b[0;32m    892\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 893\u001b[0m trace_graph, torch_out, inputs_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_get_trace_graph(\n\u001b[0;32m    894\u001b[0m     model,\n\u001b[0;32m    895\u001b[0m     args,\n\u001b[0;32m    896\u001b[0m     strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    897\u001b[0m     _force_outplace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    898\u001b[0m     _return_inputs_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    899\u001b[0m )\n\u001b[0;32m    900\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[0;32m    902\u001b[0m warn_on_static_input_change(inputs_states)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\jit\\_trace.py:1268\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[1;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(args, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m   1267\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[1;32m-> 1268\u001b[0m outs \u001b[39m=\u001b[39m ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1269\u001b[0m \u001b[39mreturn\u001b[39;00m outs\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\jit\\_trace.py:127\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(out_vars)\n\u001b[1;32m--> 127\u001b[0m graph, out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_create_graph_by_tracing(\n\u001b[0;32m    128\u001b[0m     wrapper,\n\u001b[0;32m    129\u001b[0m     in_vars \u001b[39m+\u001b[39;49m module_state,\n\u001b[0;32m    130\u001b[0m     _create_interpreter_name_lookup_fn(),\n\u001b[0;32m    131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrict,\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_force_outplace,\n\u001b[0;32m    133\u001b[0m )\n\u001b[0;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs:\n\u001b[0;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, outs[\u001b[39m0\u001b[39m], ret_inputs[\u001b[39m0\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\jit\\_trace.py:118\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs_states:\n\u001b[0;32m    117\u001b[0m     inputs_states\u001b[39m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[1;32m--> 118\u001b[0m outs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(\u001b[39m*\u001b[39;49mtrace_inputs))\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs_states:\n\u001b[0;32m    120\u001b[0m     inputs_states[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m (inputs_states[\u001b[39m0\u001b[39m], trace_inputs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1489\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
            "\u001b[1;31mTypeError\u001b[0m: Whisper.forward() missing 1 required positional argument: 'tokens'"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "\n",
        "dummy_input = torch.randn(80, 3000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N-P3paimK7a"
      },
      "source": [
        "30초 이상 오디오 데이터 처리 방법\n",
        "\n",
        "https://github.com/openai/whisper/discussions/136"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "NolAjGyKXhxT",
        "outputId": "41f74237-453b-4246-d159-ef253b80d664"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] 지정된 파일을 찾을 수 없습니다",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\user\\Desktop\\projects\\langchain_project\\유튜브_영상_요약_인공지능_빵형의_개발도상국.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/projects/langchain_project/%EC%9C%A0%ED%8A%9C%EB%B8%8C_%EC%98%81%EC%83%81_%EC%9A%94%EC%95%BD_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/projects/langchain_project/%EC%9C%A0%ED%8A%9C%EB%B8%8C_%EC%98%81%EC%83%81_%EC%9A%94%EC%95%BD_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m st \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/projects/langchain_project/%EC%9C%A0%ED%8A%9C%EB%B8%8C_%EC%98%81%EC%83%81_%EC%9A%94%EC%95%BD_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranscribe(\u001b[39m\"\u001b[39;49m\u001b[39minput.mp3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/projects/langchain_project/%EC%9C%A0%ED%8A%9C%EB%B8%8C_%EC%98%81%EC%83%81_%EC%9A%94%EC%95%BD_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m st)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/projects/langchain_project/%EC%9C%A0%ED%8A%9C%EB%B8%8C_%EC%98%81%EC%83%81_%EC%9A%94%EC%95%BD_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m][:\u001b[39m300\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\whisper\\transcribe.py:121\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[0;32m    118\u001b[0m     decode_options[\u001b[39m\"\u001b[39m\u001b[39mfp16\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m mel \u001b[39m=\u001b[39m log_mel_spectrogram(audio, padding\u001b[39m=\u001b[39;49mN_SAMPLES)\n\u001b[0;32m    122\u001b[0m content_frames \u001b[39m=\u001b[39m mel\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m N_FRAMES\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m decode_options\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\whisper\\audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[1;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(audio):\n\u001b[0;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(audio, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m         audio \u001b[39m=\u001b[39m load_audio(audio)\n\u001b[0;32m    141\u001b[0m     audio \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(audio)\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\whisper\\audio.py:59\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# fmt: on\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     out \u001b[39m=\u001b[39m run(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mstdout\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m CalledProcessError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to load audio: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mdecode()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    501\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 503\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    504\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    505\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    968\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    972\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    973\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    974\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    975\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    976\u001b[0m                         errread, errwrite,\n\u001b[0;32m    977\u001b[0m                         restore_signals,\n\u001b[0;32m    978\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    979\u001b[0m                         start_new_session)\n\u001b[0;32m    980\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    982\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py:1440\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1440\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1441\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1442\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1443\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1444\u001b[0m                              creationflags,\n\u001b[0;32m   1445\u001b[0m                              env,\n\u001b[0;32m   1446\u001b[0m                              cwd,\n\u001b[0;32m   1447\u001b[0m                              startupinfo)\n\u001b[0;32m   1448\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1449\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1454\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1456\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1457\u001b[0m                          errread, errwrite)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다"
          ]
        }
      ],
      "source": [
        "import time\n",
        "st = time.time()\n",
        "result = model.transcribe(\"input.mp3\")\n",
        "\n",
        "\n",
        "print(time.time() - st)\n",
        "\n",
        "result[\"text\"][:300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfZCB8rmZLbM",
        "outputId": "d4ef6e07-987b-4ade-baaf-c92087bf5b79"
      },
      "outputs": [],
      "source": [
        "result[\"segments\"][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gaee1ccZTgz",
        "outputId": "cc62c8a9-477a-489b-e5b6-2758c3fe0103"
      },
      "outputs": [],
      "source": [
        "len(result[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SemXn9jmRlN"
      },
      "source": [
        "## Map-reduce summarization\n",
        "\n",
        "https://python.langchain.com/docs/use_cases/summarization#option-2-map-reduce\n",
        "\n",
        "한글 설명: https://teddylee777.github.io/langchain/langchain-tutorial-07/\n",
        "\n",
        "![](https://i.imgur.com/2jJ0unq.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2qcpBZ9mY1H"
      },
      "source": [
        "### Text splitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XWJ3toqh1kZ",
        "outputId": "32a28ab5-2750-4b62-cd0e-7684c6ffd99e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema.document import Document\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=50,\n",
        "    length_function=len,\n",
        ")\n",
        "txt = '안녕하세요. 신은성입니다. 제이름은 '\n",
        "docs = [Document(page_content=x) for x in text_splitter.split_text(txt)]\n",
        "\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "len(split_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVjDfLm4jVxj",
        "outputId": "cd9b86c5-adc0-4198-c520-920fed339fdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='안녕하세요. 신은성입니다. 제이름은')]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2W1jxOXpt-E"
      },
      "source": [
        "### Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv9-YRZqZpQG"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "\n",
        "openai_api_key = \"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\"\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)\n",
        "\n",
        "# Map prompt\n",
        "map_template = \"\"\"The following is a set of documents\n",
        "{docs}\n",
        "Based on this list of docs, please identify the main themes\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "map_prompt = PromptTemplate.from_template(map_template)\n",
        "\n",
        "# Reduce prompt\n",
        "reduce_template = \"\"\"The following is set of summaries:\n",
        "{doc_summaries}\n",
        "Take these and distill it into a final, consolidated summary of the main themes.\n",
        "The final answer is a single paragraph of about 100 words and must be in Korean.\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "reduce_prompt = PromptTemplate.from_template(reduce_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV52dud-pvil"
      },
      "source": [
        "### Map-Reduce chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn-H08CYb01s"
      },
      "outputs": [],
      "source": [
        "# 1. Reduce chain\n",
        "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
        "\n",
        "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
        "combine_documents_chain = StuffDocumentsChain(\n",
        "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
        ")\n",
        "\n",
        "# Combines and iteravely reduces the mapped documents\n",
        "reduce_documents_chain = ReduceDocumentsChain(\n",
        "    # This is final chain that is called.\n",
        "    combine_documents_chain=combine_documents_chain,\n",
        "    # If documents exceed context for `StuffDocumentsChain`\n",
        "    collapse_documents_chain=combine_documents_chain,\n",
        "    # The maximum number of tokens to group documents into.\n",
        "    token_max=4000,\n",
        ")\n",
        "\n",
        "# 2. Map chain\n",
        "map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
        "\n",
        "# Combining documents by mapping a chain over them, then combining results\n",
        "map_reduce_chain = MapReduceDocumentsChain(\n",
        "    # Map chain\n",
        "    llm_chain=map_chain,\n",
        "    # Reduce chain\n",
        "    reduce_documents_chain=reduce_documents_chain,\n",
        "    # The variable name in the llm_chain to put the documents in\n",
        "    document_variable_name=\"docs\",\n",
        "    # Return the results of the map steps in the output\n",
        "    return_intermediate_steps=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W3KU9GfpySv"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "UugYRovwdXhG",
        "outputId": "64663883-fb16-44dd-c480-2bfa7e711b84"
      },
      "outputs": [],
      "source": [
        "sum_result = map_reduce_chain.run(split_docs)\n",
        "\n",
        "print(sum_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_vqmMXSXqAN"
      },
      "source": [
        "### Result\n",
        "\n",
        "주어진 문서를 기반으로 주요 주제는 다음과 같이 요약될 수 있습니다.\n",
        "\n",
        "- 첫째, 과거 친구들과의 연결감 상실: 문서는 저자가 옛 친구들과의 만남이 이전만큼 즐겁지 않다고 느끼는 이유로, 그들이 같은 이야기를 반복하고 현재의 생각과 삶에 대한 깊은 대화가 부족하다는 점을 언급합니다.\n",
        "\n",
        "- 둘째, 인생의 이정표에 대한 반성: 문서는 인생에서 중요한 순간들을 기억하고 반성하며 그 의미를 이해하는 것의 중요성을 언급합니다. 어떤 사람들은 이러한 이정표를 다른 사람들과 공유하고 이야기하기에 흥미를 느끼지 않을 수도 있다고 제안합니다.\n",
        "\n",
        "- 셋째, 나이가 들면서 인간관계의 좁아짐: 문서는 사람들이 나이가 들면서 관계가 좁아지는 경향이 있다고 제안합니다. 옛 친구들을 더 적게 만나게 되는 동시에 새로운 관계를 형성하는 데 어려움을 겪을 수도 있습니다.\n",
        "\n",
        "- 넷째, 소설에 대한 언급: 문서는 \"미셀 우열백의 세로톤이네\"라는 소설을 간단히 언급하며 인간관계의 도전과 복잡성을 묘사한다고 제안합니다. 이러한 주요 주제들은 저자의 개인적인 경험과 인간관계에 대한 사색, 그리고 인간관계의 중요성과 어려움에 관한 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eeo_4FclX6sZ"
      },
      "source": [
        "### Cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZv8DjRUpomz"
      },
      "source": [
        "![](https://i.imgur.com/zXyGdnM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvmZxgnL9TXB"
      },
      "source": [
        "## UI using Gradio\n",
        "\n",
        "외국어 -> 한국어 가능\n",
        "\n",
        "https://www.youtube.com/watch?v=BAfOGBojiEU\n",
        "\n",
        "![](https://i.imgur.com/sm2W5jE.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMi0oendkNzk",
        "outputId": "4e4b390a-3635-4dd6-e5e0-92e09082bbb2"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8qQK-xW9ZrS"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "def extract_video_id(url):\n",
        "    youtube_regex = (r'(https?://)?(www\\.)?'\n",
        "        '(youtube|youtu|youtube-nocookie)\\.(com|be)/'\n",
        "        '(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})')\n",
        "    youtube_pattern = re.compile(youtube_regex)\n",
        "    match = youtube_pattern.match(url)\n",
        "    if not match:\n",
        "        return None\n",
        "    return match.group(6)\n",
        "\n",
        "def summarize(url):\n",
        "    yt = YouTube(url)\n",
        "\n",
        "    yt.streams.filter(only_audio=True).first().download(\n",
        "        output_path='.', filename='input.mp3')\n",
        "\n",
        "    result = model.transcribe(\"input.mp3\")\n",
        "\n",
        "    docs = [Document(page_content=x) for x in text_splitter.split_text(result[\"text\"])]\n",
        "    split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "    sum_result = map_reduce_chain.run(split_docs)\n",
        "\n",
        "    video_id = extract_video_id(url)\n",
        "    embed = f\"\"\"<iframe width='560' height='315' src='https://www.youtube.com/embed/{video_id}' frameborder='0' allowfullscreen></iframe>\"\"\"\n",
        "\n",
        "    return sum_result, embed\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=summarize,\n",
        "    inputs=gr.Textbox(label=\"URL\"),\n",
        "    outputs=[gr.TextArea(label=\"Summary\"), gr.HTML()],\n",
        "    # outputs=gr.TextArea(label=\"Summary\"),\n",
        ")\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnRCeFOF_Qrn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
